---
title: "HDS 5230 High Performance Computing"
subtitle: Week 3 Assignment
output:
  pdf_document: default
  html_notebook: default
---

# Parallelization of Code

## Libraries

```{r}

library(MASS)
library(foreach)
library(doParallel)
library(tidyverse)
library(broom)
library(tictoc)

cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)

set.seed(20220206)

```

How many cores do I have?
```{r}

detectCores()
getDoParWorkers()

```
## Assignment Goals

1. Generate 100 bootstrapped sample of subsets of rows from the Boston dataset and fit a GLM on each of the samples. Perform this serially, that is, fitting of the model on the second bootstrapped sample should happen after the first model has been fit. Use medv as the outcome (which means, you would be fitting regression GLMs).

2. For each of the model, extract the (or a) statistic that represents model fit.

3. Aggregate the model fit statistics across the 100 bootstrapped samples and plot the results. Additionally compute the mean and inter-quartile range values for these test statistics.

4. Next, repeat steps 1 - 3 by executing them in parallel. For the sake of replicability, be sure to generate the same bootstrapped samples across these two sets of model-fitting operations (i.e., set a seed, and start from it for both serial and parallel generation of samples and the subsequent steps).

5. Compare the results of serial and parallel execution along the following dimensions:
    (A) are the distributions of the model fit statistics similar or different?
    (B) are the execution times for the serial and parallel approaches same or different?


# Sequential Task

First let's load in the Boston dataset.
```{r}

data(Boston)

glimpse(Boston)

```

Writing the sequential function:
```{r}

bostonSeq <- function(){
  
  fits <- c()
  
  for(i in 1:100){
    
    boot_samp <- data.frame()
    
    for(i in 1:nrow(Boston)){
      
      boot_samp <-
        rbind(
          boot_samp,
          Boston[sample(1:nrow(Boston), 1),]
        )
      
    }
    
    glm_mod <- glm(medv ~ ., data = boot_samp)
    
    fits <- append(fits, broom::glance(glm_mod)$deviance)
    
  }
  
  return(fits)
  
}

```


Does it work?
```{r, warning=FALSE}

tic()
seq_vector <- bostonSeq() 
toc()

data.frame(bootstrapped_deviance = seq_vector) %>% 
ggplot(aes(x = bootstrapped_deviance)) +
  geom_histogram(bins = 30) +
  geom_vline(xintercept = mean(seq_vector)) +
  labs(title = "Sequential Fitting", subtitle = "Bootstrapped Deviance")

summary(seq_vector)

```

Looks like it does!

# Parallel Task

Since bootstrapping the Boston dataset is presumably an inexpensive task, I will leave that for-loop be. 

```{r}

bostonPara <- function(){
  mcoptions <- list(prescedule=FALSE, set.seed=TRUE)
  fits <- foreach(1:100, .combine = 'c',
                  .packages = c('broom', 'MASS'),
                  .inorder = FALSE,
                  .options.multicore = mcoptions) %dopar% {
                    
                    data(Boston)
                    boot_samp <- data.frame()
    
                    for(i in 1:nrow(Boston)){
                      
                      boot_samp <-
                        rbind(
                          boot_samp,
                          Boston[sample(1:nrow(Boston), 1),]
                        )
                      
                    }
                    
                    glm_mod <- glm(medv ~ ., data = boot_samp)
                    
                    broom::glance(glm_mod)$deviance
                    
                  }
  
}
  
```


Did it work?

```{r}

tic()
para_vector <- bostonPara() 
toc()

data.frame(bootstrapped_deviance = para_vector) %>% 
ggplot(aes(x = bootstrapped_deviance)) +
  geom_histogram(bins = 30) +
  geom_vline(xintercept = mean(seq_vector)) +
  labs(title = "Parallel Fitting", subtitle = "Bootstrapped Deviance")

summary(para_vector)

```

Nice!

# Question Answers

How similar are the model fit statistics?

```{r}

summary(seq_vector)
summary(para_vector)

data.frame(
  sequential = seq_vector,
  paralell = para_vector
) %>% 
  pivot_longer(everything(), names_to = "Run_Type", values_to = "Deviance") %>% 
  mutate(Run_Type = as_factor(Run_Type)) %>% 
  ggplot(aes(x = Deviance, fill = Run_Type)) +
  geom_density(alpha = 0.5) +
  labs(title = "Fit Comparisons: Deviance", subtitle = "Sequential fitting vs. parallel fitting")

data.frame(
  sequential = seq_vector,
  paralell = para_vector
) %>% 
  pivot_longer(everything(), names_to = "Run_Type", values_to = "Deviance") %>% 
  mutate(Run_Type = as_factor(Run_Type)) %>% 
  ggplot(aes(y = Deviance, x = Run_Type)) +
  geom_boxplot(alpha = 0.5) +
  labs(title = "Fit Comparisons: Deviance", subtitle = "Sequential fitting vs. parallel fitting")

```

They look very similar. Not significantly different at all.

How are the execution times different?

We saw that the sequential fitting took 18 seconds while the parallel fitting only took 3 seconds. Huge speed up.
