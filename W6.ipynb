{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLU - HDS 5230 \n",
    "\n",
    "**High Performance Computing**\n",
    "\n",
    "**Week 6**\n",
    "\n",
    "**Derek Dixon**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the dask module..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Derek\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - dask\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.11.0               |   py39haa95532_0        14.4 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        14.4 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.10.3-py39haa95532_0 --> 4.11.0-py39haa95532_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "conda-4.11.0         | 14.4 MB   |            |   0% \n",
      "conda-4.11.0         | 14.4 MB   | 1          |   2% \n",
      "conda-4.11.0         | 14.4 MB   | ####5      |  45% \n",
      "conda-4.11.0         | 14.4 MB   | ########## | 100% \n",
      "conda-4.11.0         | 14.4 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "conda install dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import other required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dask.distributed import Client\n",
    "from multiprocessing import cpu_count\n",
    "import dask.dataframe as ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the CPU count and dask client via the respective class object instantiations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncores = cpu_count()\n",
    "client = Client()\n",
    "\n",
    "ncores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the .csv file. Datatypes will be defined ahead of time using a dictionary. The data will be loaded into a pandas df first, then distributed across a Dask df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join('timeseries.csv')\n",
    "\n",
    "dtype = {'locationID': object,\n",
    "       'slug': object,\n",
    "       'name': object,\n",
    "       'level': object,\n",
    "       'city': object,\n",
    "       'county': object,\n",
    "       'state': object,\n",
    "       'country': object,\n",
    "       'lat': float,\n",
    "       'long': float,\n",
    "       'population': float,\n",
    "       'aggregate': float,\n",
    "       'tz': object,\n",
    "       'cases': float,\n",
    "       'deaths': float,\n",
    "       'recovered':float,\n",
    "       'active': float,\n",
    "       'tested': float, \n",
    "       'hospitalized': float,                            \n",
    "       'hospitalized_current': float,\n",
    "       'discharged': float,\n",
    "       'icu': float,\n",
    "       'icu_current': float}\n",
    "\n",
    "data_pd = pd.read_csv(filename, parse_dates={'Date': [23]}, dtype=dtype)\n",
    "\n",
    "data = ddf.from_pandas(data_pd, npartitions = ncores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFR Per State During January 1, 2020 through February 28, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 value of states that aren't actually recognized states within the United States. I'm going to filter these out using a list. After that I will filter the data as specificed in the problem statement, then group by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_actually_states = ['American Samoa', 'Washington, D.C.', 'Guam', 'Northern Mariana Islands','Puerto Rico', 'United States Virgin Islands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.dataframe.groupby.DataFrameGroupBy at 0x21e95d06eb0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = data[(data['Date'] >= '2020-01-01') & (data['Date'] <= '2021-02-28') & (data['country'] == 'United States') & (~data.state.isin(not_actually_states))].groupby('state')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the mortality rates. We take the max of the deaths column because that column operates in a cumulative fashion. The max for a particular state would correspond to the most up-to-date value for that state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_data = (grouped.deaths.max()/grouped.population.mean()).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "Hawaii            0.000331\n",
       "Vermont           0.000697\n",
       "Maine             0.000814\n",
       "Wyoming           0.001099\n",
       "Alaska            0.001189\n",
       "Delaware          0.001251\n",
       "New Hampshire     0.001793\n",
       "Utah              0.002255\n",
       "Oregon            0.002509\n",
       "Rhode Island      0.003175\n",
       "Nevada            0.004742\n",
       "Montana           0.005120\n",
       "Washington        0.005657\n",
       "West Virginia     0.005687\n",
       "Connecticut       0.005701\n",
       "Idaho             0.006069\n",
       "Arizona           0.006273\n",
       "New Mexico        0.007248\n",
       "Maryland          0.008190\n",
       "North Dakota      0.008529\n",
       "Wisconsin         0.008657\n",
       "Massachusetts     0.009002\n",
       "South Dakota      0.009391\n",
       "Oklahoma          0.010507\n",
       "Colorado          0.011677\n",
       "California        0.012070\n",
       "Nebraska          0.012221\n",
       "Kansas            0.012698\n",
       "Indiana           0.013420\n",
       "Arkansas          0.015046\n",
       "South Carolina    0.015774\n",
       "Minnesota         0.016665\n",
       "Kentucky          0.017469\n",
       "North Carolina    0.017512\n",
       "Alabama           0.017745\n",
       "Tennessee         0.018000\n",
       "Ohio              0.018772\n",
       "Iowa              0.018944\n",
       "New Jersey        0.019826\n",
       "Missouri          0.020717\n",
       "Pennsylvania      0.021796\n",
       "Florida           0.022865\n",
       "Virginia          0.025833\n",
       "Michigan          0.030015\n",
       "Illinois          0.030573\n",
       "Louisiana         0.037724\n",
       "Mississippi       0.041554\n",
       "Georgia           0.046394\n",
       "New York          0.053781\n",
       "Texas             0.072276\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mort_data.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers appear reasonable given our prior knowledge of COVID statistics and case fatality rates.\n",
    "\n",
    "Next we compute the case fatality rates per state per month by expanding out this logic. Here we expect a 50x14 matrix (14 months as columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFR Per State Per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numexpr # https://docs.dask.org/en/latest/_modules/dask/dataframe/core.html#DataFrame.queryb\n",
    "numexpr.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it will become useful later, I will make a version of the dataset where the data column is the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_df = data[(data['Date'] >= '2020-01-01') & (data['Date'] <= '2021-02-28') & (data['country'] == 'United States') & (~data.state.isin(not_actually_states))].set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we begin defining helper functions that are intended to build off one another, representing more and more layers of aggregation. \n",
    "\n",
    "First we aggregate the sum of cases and the max of deaths per date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_stats_per_date(dt):\n",
    "    \"\"\"\n",
    "    Return the sums of cases and max of deaths for a given date across states\n",
    "    \"\"\"\n",
    "    resdf = useful_df[str(dt).split(\" \")[0]][['state', 'cases','deaths']].compute()\n",
    "    results = resdf.groupby('state').agg({'cases': 'sum', \n",
    "                                          'deaths':'max'})\n",
    "\n",
    "    results['month'] = [dt.month for i in range(len(results))]\n",
    "\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to define two series to encompass the spans of time for which we want to capture in our months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_dates = pd.Series(pd.date_range('2019-12-01', periods = 10, freq = 'M'))\n",
    "\n",
    "st_dates = seed_dates.transform(lambda dt: dt + pd.Timedelta(days=1))[:-1] \n",
    "end_dates = seed_dates[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another helper function. This one will further aggregate, cumulating the results to the monthly level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_results_monthly(ind):\n",
    "    dt_range = pd.date_range(str(st_dates[ind]).split(\" \")[0], str(end_dates[ind + 1]).split(\" \")[0])\n",
    "\n",
    "    l_rts = [agg_stats_per_date(dt_range[i]) for i in range(len(dt_range))]\n",
    "\n",
    "    comb_results = pd.concat(l_rts)\n",
    "    cum_rt = comb_results.groupby(['state','month']).agg({'cases': 'sum', 'deaths': 'max'})\n",
    "    \n",
    "    return(cum_rt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply pass each monthly index to the function and store the results in a list using a list comprehension. We can then convert that list back into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derek\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:4052: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <th>1.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <th>1.0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <th>9.0</th>\n",
       "      <td>8139620.0</td>\n",
       "      <td>3208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <th>9.0</th>\n",
       "      <td>4834796.0</td>\n",
       "      <td>2126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <th>9.0</th>\n",
       "      <td>788988.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>9.0</th>\n",
       "      <td>5756751.0</td>\n",
       "      <td>1327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <th>9.0</th>\n",
       "      <td>280106.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         cases  deaths\n",
       "state         month                   \n",
       "Alabama       1.0          0.0     0.0\n",
       "Alaska        1.0          0.0     0.0\n",
       "Arizona       1.0         12.0     0.0\n",
       "Arkansas      1.0          0.0     0.0\n",
       "California    1.0         35.0     0.0\n",
       "...                        ...     ...\n",
       "Virginia      9.0    8139620.0  3208.0\n",
       "Washington    9.0    4834796.0  2126.0\n",
       "West Virginia 9.0     788988.0   350.0\n",
       "Wisconsin     9.0    5756751.0  1327.0\n",
       "Wyoming       9.0     280106.0    50.0\n",
       "\n",
       "[450 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_c_results = [cum_results_monthly(i) for i in range(0,9)]\n",
    "\n",
    "full_results = pd.concat(l_c_results)\n",
    "\n",
    "full_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the CFR as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>CFR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <th>1.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <th>1.0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <th>9.0</th>\n",
       "      <td>8139620.0</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <th>9.0</th>\n",
       "      <td>4834796.0</td>\n",
       "      <td>2126.0</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <th>9.0</th>\n",
       "      <td>788988.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>9.0</th>\n",
       "      <td>5756751.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <th>9.0</th>\n",
       "      <td>280106.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         cases  deaths       CFR\n",
       "state         month                             \n",
       "Alabama       1.0          0.0     0.0  0.000000\n",
       "Alaska        1.0          0.0     0.0  0.000000\n",
       "Arizona       1.0         12.0     0.0  0.000000\n",
       "Arkansas      1.0          0.0     0.0  0.000000\n",
       "California    1.0         35.0     0.0  0.000000\n",
       "...                        ...     ...       ...\n",
       "Virginia      9.0    8139620.0  3208.0  0.000394\n",
       "Washington    9.0    4834796.0  2126.0  0.000440\n",
       "West Virginia 9.0     788988.0   350.0  0.000444\n",
       "Wisconsin     9.0    5756751.0  1327.0  0.000231\n",
       "Wyoming       9.0     280106.0    50.0  0.000179\n",
       "\n",
       "[450 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results['CFR'] = full_results['deaths']/full_results['cases']\n",
    "full_results['CFR'] = full_results['CFR'].replace(np.nan, 0)\n",
    "\n",
    "full_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Closing Thoughts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I think it makes a lot of sense to use dask and distributed computing amongst the various cores. Aggregating the results took 7+ minutes, by far the most expensive computation of the assignment. That is with the usage of all my machines cores (24 cores). I can imagine it taking much longer if it were done the old fashion way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFR Changes Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue to build off the final answer from above. We will start with a helper function to accumulate the CFRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_CFRs(st, ulimit = 9, llimit = 1):\n",
    "    \"\"\"\n",
    "    Returns aggregated change in the CFR lagged differences for a given state, st.\n",
    "    Lag: between current and previous time period, starting at period 2.\n",
    "    \"\"\"  \n",
    "    return sum([full_results.loc[(st, i)].CFR - full_results.loc[(st, i-1)].CFR for i in range(llimit+1, ulimit+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to be able to pass the states in from a list so here I will form such a list. Somehow the list will contain nans if left unchecked so I've included a line of code to drop the nans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "l_states = useful_df.state.unique().compute().tolist()\n",
    "\n",
    "l_states = [x for x in l_states if pd.isnull(x) == False]\n",
    "\n",
    "print(len(l_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the results by mapping the values of l_states (our state list) to the helper function, which we will store in a list. We then have two lists which we can pass to a pandas dataframe as our final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_CFR_cum_deltas = list(map(lambda s: cum_CFRs(s), l_states))\n",
    "\n",
    "out_df = pd.DataFrame({'state': l_states, \n",
    "                       'agg_CFR_change': l_CFR_cum_deltas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>agg_CFR_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Utah</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Montana</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.000320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>0.000339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Florida</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Texas</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>0.000420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Maine</td>\n",
       "      <td>0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>0.000541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>0.000835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>New York</td>\n",
       "      <td>0.001236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>0.001277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>0.001315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>0.001418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state  agg_CFR_change\n",
       "38            Utah        0.000100\n",
       "49          Alaska        0.000141\n",
       "48         Wyoming        0.000179\n",
       "44        Nebraska        0.000202\n",
       "24          Hawaii        0.000208\n",
       "33    South Dakota        0.000211\n",
       "22           Idaho        0.000215\n",
       "7           Kansas        0.000220\n",
       "15       Wisconsin        0.000231\n",
       "32       Tennessee        0.000236\n",
       "28        Oklahoma        0.000237\n",
       "43    North Dakota        0.000248\n",
       "23            Iowa        0.000293\n",
       "34         Montana        0.000307\n",
       "35  North Carolina        0.000312\n",
       "27          Oregon        0.000313\n",
       "45        Arkansas        0.000318\n",
       "47         Alabama        0.000320\n",
       "3         Kentucky        0.000339\n",
       "0       California        0.000346\n",
       "19         Florida        0.000356\n",
       "39          Nevada        0.000358\n",
       "11        Missouri        0.000377\n",
       "26           Texas        0.000383\n",
       "6         Virginia        0.000394\n",
       "9        Minnesota        0.000401\n",
       "14         Georgia        0.000405\n",
       "29  South Carolina        0.000420\n",
       "1       Washington        0.000440\n",
       "16   West Virginia        0.000444\n",
       "46         Arizona        0.000447\n",
       "13           Maine        0.000475\n",
       "17        Colorado        0.000541\n",
       "36     Mississippi        0.000542\n",
       "21        Illinois        0.000544\n",
       "37      New Mexico        0.000552\n",
       "12        Maryland        0.000561\n",
       "5        Louisiana        0.000566\n",
       "4          Vermont        0.000572\n",
       "31            Ohio        0.000573\n",
       "30    Rhode Island        0.000835\n",
       "8          Indiana        0.000886\n",
       "25    Pennsylvania        0.000899\n",
       "41   New Hampshire        0.000942\n",
       "10        Michigan        0.000964\n",
       "42        New York        0.001236\n",
       "2    Massachusetts        0.001277\n",
       "20        Delaware        0.001315\n",
       "40      New Jersey        0.001349\n",
       "18     Connecticut        0.001418"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.sort_values('agg_CFR_change')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Closing Thoughts**\n",
    "\n",
    "Here we're dealing with the post-processed result from the prior question, which is much much smaller. In this case, Dask/distributed computations are not necessary. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d71b46adc045dc266d76bf863c41704038796277397a722f815225575bfc4d64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
